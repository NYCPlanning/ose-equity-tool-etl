{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import simplejson\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER = \"output\"\n",
    "\n",
    "category_folders = {\n",
    "  \"demo\": \"demographics\",\n",
    "  \"econ\": \"economics\",\n",
    "  \"hsaq\": \"housing_security\",\n",
    "  \"hopd\": \"housing_production\",\n",
    "  \"qlao\": \"quality_of_life\"\n",
    "}\n",
    "\n",
    "DO_EDM_URL = \"https://edm-publishing.nyc3.digitaloceanspaces.com/db-eddt\"\n",
    "DO_CHANGE_URL = \"https://equity-tool-data.nyc3.digitaloceanspaces.com/change\"\n",
    "\n",
    "geography_column_names = {\n",
    "  \"district\": \"puma\",\n",
    "  \"borough\": \"borough\",\n",
    "  \"citywide\": \"citywide\"\n",
    "}\n",
    "\n",
    "borough_map = {\n",
    "      \"MN\": \"1\",\n",
    "      \"BX\": \"2\",\n",
    "      \"BK\": \"3\",\n",
    "      \"QN\": \"4\",\n",
    "      \"SI\": \"5\"\n",
    "    }\n",
    "\n",
    "subgroup_tokens = {\n",
    "  \"tot\": \"\",\n",
    "  \"anh\": \"_anh\",\n",
    "  \"bnh\": \"_bnh\",\n",
    "  \"wnh\": \"_wnh\",\n",
    "  \"hsp\": \"_hsp\"\n",
    "}\n",
    "\n",
    "variances = {\n",
    "  \"NONE\": {\n",
    "    \"token\": \"\"\n",
    "  },\n",
    "  \"MOE\": {\n",
    "    \"token\": \"_moe\"\n",
    "  },\n",
    "  \"CV\": {\n",
    "    \"token\": \"_cv\"\n",
    "  }\n",
    "}\n",
    "\n",
    "measures = {\n",
    "  \"COUNT\": {\n",
    "    \"token\": \"_count\"\n",
    "  },\n",
    "  \"PERCENT\": {\n",
    "    \"token\": \"_pct\"\n",
    "  },\n",
    "  \"RATE\": {\n",
    "    \"token\": \"_rate\"\n",
    "  },\n",
    "  \"INDEX\": {\n",
    "    \"token\": \"_index\"\n",
    "  },\n",
    "  \"MEDIAN\": {\n",
    "    \"token\": \"_median\"\n",
    "  },\n",
    "  \"PERCENTAGE_POINT\": {\n",
    "    \"token\": \"_pnt\"\n",
    "  }\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "  file = open(path, 'r')\n",
    "  return json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the tables we have to display on the front end show values that don't actually map to any columns in the source data from EDM\n",
    "# This usually happens in rows that are the \"denominator\" of the table so logically don't have data for percent and percent moe\n",
    "# When this happens, the build_config function will build column names that don't actually exist in the csv we are looking at\n",
    "# This variable gives us a way to append columns to the csvs we load in with \"hard coded\" values\n",
    "# This variable is a dictionary whose keys are filenames of the csvs EDM gives us. The values are arrays of tuples. The first\n",
    "# item of each tuple is the column name you want to add to the file, the second item is the value for that column\n",
    "appended_columns = {\n",
    "  \"housing_security_puma\": [(\"units_occurental_pct\", 100),(\"units_occurental_pct_moe\", 0), (\"units_occu_pct\", 100), (\"units_occu_pct_moe\", 0)],\n",
    "  \"housing_security_borough\": [(\"units_occurental_pct\", 100),(\"units_occurental_pct_moe\", 0), (\"units_occu_pct\", 100), (\"units_occu_pct_moe\", 0)],\n",
    "  \"housing_security_citywide\": [(\"units_occurental_pct\", 100),(\"units_occurental_pct_moe\", 0), (\"units_occu_pct\", 100), (\"units_occu_pct_moe\", 0)],\n",
    "  \"housing_production_puma\": [(\"units_hi_newconstruction_count\",0),(\"units_hi_preservation_count\",0),(\"total_pct\", 100)],\n",
    "  \"housing_production_borough\": [(\"units_hi_newconstruction_count\",0),(\"units_hi_preservation_count\",0),(\"total_pct\", 100)],\n",
    "  \"housing_production_citywide\": [(\"units_hi_newconstruction_count\",0),(\"units_hi_preservation_count\",0),(\"total_pct\", 100)],\n",
    "}\n",
    "\n",
    "for year in [\"_2000\",\"_0812\",\"_1519\"]:\n",
    "  for geography in [\"_puma\",\"_borough\",\"_citywide\"]:\n",
    "    columns = []\n",
    "    for subgroup in [\"\",\"_anh\",\"_bnh\",\"_wnh\",\"_hsp\"]:\n",
    "      columns = columns + [(f'age_median{subgroup}{var}', np.nan) for var in [\"_pct\",\"_pct_moe\"]]\n",
    "    appended_columns[f'demographics{year}{geography}'] = columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloads EDM csv file for given geography, category, and filename\n",
    "# Sets column containing geoids as index, and adds column axis multi-index with value of filename\n",
    "def download_df(geography, category, filename):\n",
    "  base_url = DO_CHANGE_URL if \"change\" in filename else DO_EDM_URL\n",
    "  df = pd.read_csv(f'{base_url}/{category_folders[category]}/{filename}.csv', dtype={geography_column_names[geography]: \"str\"})\n",
    "  if filename in appended_columns:\n",
    "    for column_name, value in appended_columns[filename]:\n",
    "      df[column_name] = value\n",
    "  if geography == \"district\":\n",
    "    df[geography_column_names[geography]] = df[geography_column_names[geography]].str.lstrip('0')\n",
    "  df = df.set_index(geography_column_names[geography])\n",
    "\n",
    "  df.columns = pd.MultiIndex.from_tuples([(filename, col_name) for col_name in df.columns.tolist()], names=[\"file\",\"column\"])\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursively deep merges two dictionaries and returns the result\n",
    "# https://stackoverflow.com/a/20666342\n",
    "def merge(source, destination):\n",
    "    for key, value in source.items():\n",
    "        if isinstance(value, dict):\n",
    "            node = destination.setdefault(key, {})\n",
    "            merge(value, node)\n",
    "        else:\n",
    "            destination[key] = value\n",
    "\n",
    "    return destination\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build Table Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "  \"demo\": load_json(\"../config/demo.json\"),\n",
    "  \"econ\": load_json(\"../config/econ.json\"),\n",
    "  \"hsaq\": load_json(\"../config/hsaq.json\"),\n",
    "  \"hopd\": load_json(\"../config/hopd.json\"),\n",
    "  \"qlao\": load_json(\"../config/qlao.json\")\n",
    "}\n",
    "\n",
    "resolved_tables = {\n",
    "  \"district\": {\n",
    "    \"hsaq\": {\n",
    "      \"tot\": [],\n",
    "      \"anh\": [],\n",
    "      \"bnh\": [],\n",
    "      \"wnh\": [],\n",
    "      \"hsp\": []\n",
    "    }\n",
    "  },\n",
    "  \"borough\": {\n",
    "    \"hsaq\": {\n",
    "      \"tot\": [],\n",
    "      \"anh\": [],\n",
    "      \"bnh\": [],\n",
    "      \"wnh\": [],\n",
    "      \"hsp\": []\n",
    "    }\n",
    "  },\n",
    "  \"citywide\": {\n",
    "    \"hsaq\": {\n",
    "      \"tot\": [],\n",
    "      \"anh\": [],\n",
    "      \"bnh\": [],\n",
    "      \"wnh\": [],\n",
    "      \"hsp\": []\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# Loops through configuration files and saves result to /generated/resolved_table_configs.json with a fully\n",
    "# formed table config for every indicator, for every geography, for every subgroup\n",
    "for category, table_list in config.items():\n",
    "  for table_config in table_list:\n",
    "    base = table_config[\"base\"].copy()\n",
    "    for geography, geography_config in table_config[\"geographies\"].items():\n",
    "      geo_config = geography_config.copy()\n",
    "      if geography not in resolved_tables:\n",
    "        resolved_tables[geography] = {}\n",
    "      if category not in resolved_tables[geography]:\n",
    "        resolved_tables[geography][category] = {}\n",
    "      base = table_config[\"base\"]\n",
    "      merged_table_config = merge(base, geo_config)\n",
    "      for subgroup, subgroup_config in table_config[\"subgroups\"].items():\n",
    "        sub_config = subgroup_config.copy()\n",
    "        if subgroup not in resolved_tables[geography][category]: \n",
    "          resolved_tables[geography][category][subgroup] = []\n",
    "        final = merge(merged_table_config, sub_config)\n",
    "        resolved_tables[geography][category][subgroup].append(final)\n",
    "\n",
    "with open(f'../generated/resolved_table_configs.json', 'w') as fp:\n",
    "    simplejson.dump(resolved_tables, fp, ignore_nan=True, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build Page Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_column_name(variable, subgroup, measure, variance, year=\"\", subcategory=\"\", suffix=\"\"):\n",
    "  measure_token = measures[measure][\"token\"]\n",
    "  variance_token = variances[variance][\"token\"]\n",
    "  return f'{subcategory}{variable}{suffix}{year}{subgroup_tokens[subgroup]}{measure_token}{variance_token}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The values in the \"measures\" list for change over time vintages will be different than the list\n",
    "# that describes the non-change vintages but we can figure out what it will be based on the list for\n",
    "# the non-change vintages, this saves us from having to define them manually for every indicator with a change vintage\n",
    "def get_change_measures(measures):\n",
    "  if measures == [\"COUNT\", \"COUNT\", \"COUNT\", \"PERCENT\", \"PERCENT\"]:\n",
    "    return [\"COUNT\", \"COUNT\", \"PERCENT\",\"PERCENT\", \"PERCENTAGE_POINT\", \"PERCENTAGE_POINT\"]\n",
    "  elif measures == [\"MEDIAN\", \"MEDIAN\", \"MEDIAN\", \"PERCENT\", \"PERCENT\"]:\n",
    "    return [\"MEDIAN\", \"MEDIAN\", \"PERCENT\",\"PERCENT\", \"PERCENTAGE_POINT\", \"PERCENTAGE_POINT\"]\n",
    "  elif measures == [\"COUNT\", \"PERCENT\"]:\n",
    "    return [\"COUNT\", \"PERCENT\", \"PERCENTAGE_POINT\"]\n",
    "  elif measures == [\"COUNT\", \"COUNT\", \"COUNT\"]:\n",
    "    return [\"COUNT\",\"COUNT\",\"PERCENT\",\"PERCENT\"]\n",
    "  elif measures == [\"MEDIAN\", \"MEDIAN\", \"MEDIAN\"]:\n",
    "    return [\"MEDIAN\", \"MEDIAN\", \"PERCENT\", \"PERCENT\"]\n",
    "  elif measures == [\"RATE\"]:\n",
    "    return [\"RATE\", \"PERCENT\"]\n",
    "  elif measures == [\"COUNT\"]:\n",
    "    return [\"COUNT\", \"PERCENT\"]\n",
    "  else:\n",
    "    print(f'could not find value for measures {measures}')\n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function does the same thing as get_change_measures but for variances\n",
    "def get_change_variances(variances):\n",
    "  if variances == [\"NONE\", \"MOE\", \"CV\", \"NONE\", \"MOE\"]:\n",
    "    return [\"NONE\", \"MOE\",\"NONE\", \"MOE\",\"NONE\", \"MOE\"]\n",
    "  elif variances == [\"NONE\", \"NONE\"]:\n",
    "    return [\"NONE\", \"NONE\", \"NONE\"]\n",
    "  elif variances == [\"NONE\", \"MOE\", \"CV\"]:\n",
    "    return [\"NONE\", \"MOE\", \"NONE\", \"MOE\"]\n",
    "  elif variances == [\"NONE\"]:\n",
    "    return [\"NONE\", \"PERCENT\"]\n",
    "  else:\n",
    "    print(f'could not find value for variances {variances}')\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In most cases, we can derive what the value of \"headers\" should be based on\n",
    "# \"measures\". This function handles that, allowing us to remove the repetitive\n",
    "# header values from the config files\n",
    "def get_headers(measures):\n",
    "  if measures == [\"COUNT\", \"COUNT\", \"COUNT\", \"PERCENT\", \"PERCENT\"]:\n",
    "    return [[[\"number\", 3],[\"percent\", 2]],[[\"estimate\", 1],[\"moe\", 1],[\"cv\", 1],[\"estimate\", 1],[\"moe\", 1]]]\n",
    "  elif measures == [\"COUNT\", \"PERCENT\"]:\n",
    "    return [[[\"number\", 1],[\"percent\", 1]]]\n",
    "  elif measures == [\"COUNT\", \"COUNT\", \"COUNT\"]:\n",
    "    return [[[\"number\", 3]],[[\"estimate\", 1],[\"moe\", 1],[\"cv\", 1]]]\n",
    "  elif measures == [\"MEDIAN\", \"MEDIAN\", \"MEDIAN\"]:\n",
    "    return [[[\"number\", 3]],[[\"estimate\", 1],[\"moe\", 1],[\"cv\", 1]]]\n",
    "  elif measures == [\"RATE\"]:\n",
    "    return [[[\"number\", 1]]]\n",
    "  elif measures == [\"COUNT\"]:\n",
    "    return [[[\"number\", 1]]],\n",
    "  elif measures == [\"INDEX\"]:\n",
    "    return [[[\"score 1-5\", 1]]]\n",
    "  else:\n",
    "    print(f'could not find headers value for measures {measures}')\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function does the same thing as get_headers but for headers of \n",
    "# change over time vintages\n",
    "def get_change_headers(measures):\n",
    "  if measures == [\"COUNT\", \"COUNT\", \"COUNT\", \"PERCENT\", \"PERCENT\"]:\n",
    "    return [[[\"number\", 2],[\"percent\", 2],[\"pctg. pt.\", 2]],[[\"estimate\", 1],[\"moe\", 1],[\"estimate\", 1],[\"moe\", 1],[\"estimate\", 1],[\"moe\", 1]]]\n",
    "  elif measures == [\"COUNT\", \"PERCENT\"]:\n",
    "    return [[[\"number\", 1],[\"percent\", 1],[\"pctg. pt.\", 1]]]\n",
    "  elif measures == [\"COUNT\", \"COUNT\", \"COUNT\"]:\n",
    "    return [[[\"number\", 2],[\"percent\", 2]],[[\"estimate\", 1],[\"moe\", 1],[\"estimate\", 1],[\"moe\", 1]]]\n",
    "  elif measures == [\"MEDIAN\", \"MEDIAN\", \"MEDIAN\"]:\n",
    "    return [[[\"number\", 2],[\"percent\", 2]],[[\"estimate\", 1],[\"moe\", 1],[\"estimate\", 1],[\"moe\", 1]]]\n",
    "  elif measures == [\"RATE\"]:\n",
    "    return [[[\"number\", 1],[\"percent\", 1]]],\n",
    "  elif measures == [\"COUNT\"]:\n",
    "    return [[[\"number\", 1],[\"percent\", 1]]],\n",
    "  else:\n",
    "    print(f'could not find change headers value for measures {measures}')\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_config(table_config, subgroup):  \n",
    "  result = {}\n",
    "\n",
    "  # Copy properties of table_config that should be mapped directly into\n",
    "  # the built config\n",
    "  # result[\"headers\"] = table_config[\"headers\"]\n",
    "  result[\"title\"] = table_config[\"title\"]\n",
    "  result[\"vintages\"] = table_config[\"vintages\"]\n",
    "  result[\"files\"] = table_config[\"files\"]\n",
    "  result[\"labels\"] = table_config[\"labels\"]\n",
    "  result[\"variances\"] = [table_config[\"variances\"] for i in table_config[\"labels\"]]\n",
    "  result[\"is_survey\"] = table_config.get(\"is_survey\", False)\n",
    "\n",
    "  # Some tables (like \"age\" in demographic conditions) don't have the same \"measures\" values for all of the non-denom rows.\n",
    "  # \"age\" has COUNTs for the first three but MEDIANs for the final row. This check allows you to set table_config[\"measures\"] to\n",
    "  # a 2d array when you need to explicitly pass different values for each non-denom row\n",
    "  if isinstance(table_config[\"measures\"][0],list):\n",
    "    result[\"measures\"] = table_config[\"measures\"]\n",
    "  else:\n",
    "    result[\"measures\"] = [table_config[\"measures\"] for i in table_config[\"labels\"]]\n",
    "  if \"suffixes\" in table_config:\n",
    "    result[\"suffixes\"] = table_config[\"suffixes\"]\n",
    "  variables = [variable for variable in table_config[\"variables\"]]\n",
    "  if \"headers\" in table_config:\n",
    "    result[\"headers\"] = table_config[\"headers\"]\n",
    "  else:\n",
    "    result[\"headers\"] = get_headers(result[\"measures\"][0])\n",
    "\n",
    "  # If denominator is present, set a flag on result and prepend its label, measures, and variances\n",
    "  if \"denominator\" in table_config:\n",
    "    result[\"has_denominator\"] = True\n",
    "    result[\"labels\"].insert(0, table_config[\"denominator\"][\"label\"])\n",
    "    result[\"measures\"].insert(0, table_config[\"denominator\"][\"measures\"])\n",
    "    result[\"variances\"].insert(0, table_config[\"denominator\"][\"variances\"])\n",
    "    variables.insert(0, table_config[\"denominator\"][\"variable\"])\n",
    "  else:\n",
    "    result[\"has_denominator\"] = False\n",
    "\n",
    "  # if \"has_change\" in table_config:\n",
    "  #   print(merge(table_config[\"change\"][\"denominator\"], table_config[\"denominator\"])[\"label\"])\n",
    "\n",
    "  result[\"upper_limits\"] = [[None for j in result[\"labels\"]] for i in result[\"vintages\"]]\n",
    "  result[\"lower_limits\"] = [[None for j in result[\"labels\"]] for i in result[\"vintages\"]]\n",
    "  if \"upper_limits\" in table_config:\n",
    "    result[\"upper_limits\"] = table_config[\"upper_limits\"]\n",
    "  if \"lower_limits\" in table_config:\n",
    "    result[\"lower_limits\"] = table_config[\"lower_limits\"]\n",
    "  \n",
    "  # If table config has \"placeholder\", it has no data so skip building column names\n",
    "  if \"placeholder\" in table_config:\n",
    "    result[\"placeholder\"] = table_config[\"placeholder\"]\n",
    "  else: \n",
    "    # \"cells\" is a three dimensional array of the fully formed column names for each data point\n",
    "    # The outer-most array has one item per vintage\n",
    "    # The second level arrays have one item per row (including one for \"denominator\" rows)\n",
    "    # the inner-most array has one item (a string of the full column name) per cell in a row\n",
    "    result[\"cells\"] = []\n",
    "    for i in range(len(table_config[\"vintages\"])):\n",
    "      column_vintage = []\n",
    "      \n",
    "      # Some indicators contain data where the vintage is a part of the column name. In those cases,\n",
    "      # table_config should have an array of strings called \"years\" where each string is the \"year\" token\n",
    "      # for each vintage. The indices of \"years\" match up those in \"vintages\"\n",
    "      year = \"\"\n",
    "      if \"years\" in table_config:\n",
    "        year = table_config[\"years\"][i]\n",
    "\n",
    "      # variables is an array of strings containing the \"variable\" token for each row in the table, including the one for\n",
    "      # the denominator, if there is one\n",
    "      for j, variable in enumerate(variables):\n",
    "        column_row = []\n",
    "        suffixes = [\"\" for i in result[\"variances\"][0]]\n",
    "        # Some tables require us to add tokens to the \"variable\" token from one cell to the next across the same\n",
    "        # row. \"suffixes\" is an optional property in table config that allows us to add those by mapping strings to cells\n",
    "        # within a row, similar to how measures and variances are mapped in\n",
    "        # If the table_config doesn't specify suffixes, create an array of empty strings with the same length as\n",
    "        # measures and variances\n",
    "        if \"suffixes\" in table_config:\n",
    "          suffixes = table_config[\"suffixes\"]\n",
    "        for measure, variance, suffix in tuple(zip(result[\"measures\"][j], result[\"variances\"][j], suffixes)):\n",
    "          # Most tables belong to a given \"subcategory\" (ex: edu, health, etc) that is communicated by a token that comes at\n",
    "          # the beginning of the token. \n",
    "          _subcategory = \"\"\n",
    "          _subgroup = subgroup\n",
    "          if j == 0 and \"denominator\" in table_config:\n",
    "            if \"subcategory\" in table_config[\"denominator\"]:\n",
    "              _subcategory = table_config[\"denominator\"][\"subcategory\"]\n",
    "            # The \"Mutually Exclusive Race/Hispanic Origin\" table's denominator shows the total population \"pop\" column,\n",
    "            # even when viewing the page for a subgroup so we need a special flag to make sure the code doesn't\n",
    "            # insert the subgroup token in those cases\n",
    "            if \"ignore_subgroup\" in table_config[\"denominator\"] and table_config[\"denominator\"][\"ignore_subgroup\"] == True:\n",
    "              _subgroup = \"tot\"\n",
    "          elif \"subcategory\" in table_config:\n",
    "            _subcategory = table_config[\"subcategory\"]\n",
    "          column_row.append(build_column_name(variable, _subgroup, measure, variance, year, _subcategory, suffix))\n",
    "        column_vintage.append(column_row)\n",
    "      result[\"cells\"].append(column_vintage)\n",
    "  return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolved_tables = load_json('../generated/resolved_table_configs.json')\n",
    "output = {}\n",
    "for geography, geography_config in resolved_tables.items():\n",
    "  if geography not in output:\n",
    "    output[geography] = {}\n",
    "  for category, category_config in geography_config.items():\n",
    "    if category not in output[geography]:\n",
    "      output[geography][category] = {}\n",
    "    for subgroup, subgroup_config in category_config.items():\n",
    "      if subgroup not in output[geography][category]:\n",
    "        output[geography][category][subgroup] = []\n",
    "      for table_config in subgroup_config:\n",
    "        output[geography][category][subgroup].append(build_config(table_config, subgroup))\n",
    "\n",
    "with open(f'../generated/resolved_pages.json', 'w') as fp:\n",
    "    simplejson.dump(output, fp, ignore_nan=True, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cell(value, measure, variance):\n",
    "  new_cell = {}\n",
    "  if np.isnan(value):\n",
    "    new_cell[\"value\"] = None\n",
    "  else:\n",
    "    new_cell[\"value\"] = value\n",
    "  new_cell[\"measure\"] = measure\n",
    "  new_cell[\"variance\"] = variance\n",
    "  return new_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_row(label, values, measures, variances, upper_limit = None, lower_limit = None):\n",
    "  new_row = {\n",
    "    \"label\": label,\n",
    "    \"isDenominator\": False,\n",
    "    \"cells\": []\n",
    "  }\n",
    "  for k in range(len(values)):\n",
    "    new_cell = build_cell(values[k], measures[k], variances[k])\n",
    "    if k == 0 and upper_limit is not None and values[k] == upper_limit:\n",
    "      new_cell[\"coding\"] = \"TOP\"\n",
    "    if k == 0 and lower_limit is not None and values[k] == lower_limit:\n",
    "      new_cell[\"coding\"] = \"BOTTOM\"\n",
    "    new_row[\"cells\"].append(new_cell)\n",
    "  \n",
    "  if \"CV\" in variances:\n",
    "    cv = values[variances.index(\"CV\")]\n",
    "    is_reliable = True\n",
    "    if np.isnan(cv) or cv >= 20:\n",
    "      is_reliable = False\n",
    "    for cell in new_row[\"cells\"]:\n",
    "      cell[\"isReliable\"] = is_reliable\n",
    "  return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_placeholder_row(label, placeholder):\n",
    "  new_row = {\n",
    "    \"label\": label,\n",
    "    \"isDenominator\": False,\n",
    "    \"cells\": None,\n",
    "    \"placeholder\": placeholder\n",
    "  }\n",
    "  return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table config takes a list of table config objects and a row of a DataFrame (a pandas Series)\n",
    "# It builds the final output to be consumed by the front end for a given geography, geoid, category combination\n",
    "def build_vintages(table_list, df_row):\n",
    "  result = []\n",
    "  for table_config in table_list:\n",
    "    indicator = {}\n",
    "    indicator[\"title\"] = table_config.get(\"title\", \"\")\n",
    "    indicator[\"isSurvey\"] = table_config[\"is_survey\"]\n",
    "    indicator[\"vintages\"] = []\n",
    "    for vintage_index, vintage_label in enumerate(table_config[\"vintages\"]):\n",
    "      new_vintage = {}\n",
    "      new_vintage[\"label\"] = vintage_label\n",
    "      new_vintage[\"headers\"] = build_column_headers(table_config[\"headers\"])\n",
    "      new_vintage[\"rows\"] = []\n",
    "      if \"placeholder\" in table_config:\n",
    "        for label in table_config[\"labels\"]:\n",
    "          new_row = build_placeholder_row(label, table_config[\"placeholder\"])\n",
    "          new_vintage[\"rows\"].append(new_row)\n",
    "      else:\n",
    "        vintage_cells = table_config[\"cells\"][vintage_index]\n",
    "        file_for_vintage = table_config[\"files\"][vintage_index]\n",
    "        for row_index, cells_row in enumerate(vintage_cells):\n",
    "          values = df_row[file_for_vintage][cells_row].to_list()\n",
    "          new_row = build_row(\n",
    "            table_config[\"labels\"][row_index],\n",
    "            values,\n",
    "            table_config[\"measures\"][row_index],\n",
    "            table_config[\"variances\"][row_index],\n",
    "            table_config[\"upper_limits\"][vintage_index][row_index],\n",
    "            table_config[\"lower_limits\"][vintage_index][row_index]\n",
    "          )\n",
    "          new_vintage[\"rows\"].append(new_row)\n",
    "      if table_config[\"has_denominator\"] == True:\n",
    "        new_vintage[\"rows\"][0][\"isDenominator\"] = True\n",
    "      indicator[\"vintages\"].append(new_vintage)\n",
    "    result.append(indicator)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resolved_pages is an object with a key for each geography\n",
    "# each geography is an object with a key for each category\n",
    "# each category is an object with a key for each subgroup (including \"tot\" for total pop)\n",
    "# each subgroup is a an array of objects, with an object for each indicator in that given category\n",
    "# each of those objects contains all the information needed to look up the data and build\n",
    "# the JSON necessary to display that table for every geoid in the geography\n",
    "output = {}\n",
    "with open('../generated/resolved_pages.json', 'r') as pages_file:\n",
    "    pages = json.load(pages_file)\n",
    "    for geography, geography_config in pages.items():\n",
    "      if geography not in output:\n",
    "        output[geography] = {}\n",
    "      for category, category_config in geography_config.items():\n",
    "        if category not in output[geography]:\n",
    "          output[geography][category] = {}\n",
    "        # First, download all csv's necessary to have all data for the given\n",
    "        # geography an category, and combine them into one DataFrame\n",
    "        # with a multi-index on the column access that conveys filename\n",
    "        df = pd.DataFrame()\n",
    "        for subgroup, table_list in category_config.items():\n",
    "          for table_config in table_list:\n",
    "            if \"files\" in table_config and \"placeholder\" not in table_config:\n",
    "              for file in table_config[\"files\"]:\n",
    "                if df.empty:\n",
    "                  df = download_df(geography, category, file)\n",
    "                else:\n",
    "                  if file not in df.columns.levels[0].tolist():\n",
    "                    df_for_file = download_df(geography, category, file)\n",
    "                    df = df.merge(df_for_file, left_index=True, right_index=True)\n",
    "        # Iterate through each row in the combined DataFrame\n",
    "        for _geoid, df_row in df.iterrows():\n",
    "          geoid = _geoid\n",
    "          if geography == \"citywide\":\n",
    "            geoid = \"nyc\"\n",
    "          if geography == \"borough\":\n",
    "            geoid = borough_map[geoid]\n",
    "          if geoid not in output[geography][category]:\n",
    "            output[geography][category][geoid] = {}\n",
    "          area = output[geography][category][geoid]\n",
    "          # For each geoid, call build_vintages to build the final output for that geoid and category\n",
    "          for subgroup, table_list in category_config.items():\n",
    "            if subgroup not in area:\n",
    "              area[subgroup] = build_vintages(table_list, df_row)\n",
    "\n",
    "\n",
    "# Finally, iterate through geoid in the output object and save that data to a file\n",
    "# containing all data for the given geoid and category. Each file will be a object\n",
    "# with a key for each subgroup (including \"tot\"). Each of those will be an array\n",
    "# of objects for the tables in that subgroup for the geoid\n",
    "\n",
    "for geography, categories in output.items():\n",
    "  for category, areas in categories.items():\n",
    "    for geoid, data in areas.items():\n",
    "      with open(f'../output/{geography}_{geoid}_{category}.json', 'w') as fp:\n",
    "        simplejson.dump(data, fp, ignore_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "394c62ab563a469ed0fc70e322f10c53ee4992e994668222c9e8a883c64e5e69"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
